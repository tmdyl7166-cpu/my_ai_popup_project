#!/usr/bin/env python3
"""
å…¨å±€ä¸Šä¸‹æ–‡ç›‘æ§å™¨è„šæœ¬
ç›‘æ§æ•´ä¸ªé¡¹ç›®çš„å…¨å±€ä¸Šä¸‹æ–‡å…³è”æ€§ï¼Œç¡®ä¿æ‰€æœ‰è·¯å¾„å’Œæ–‡ä»¶çš„å…³è”æ€§æ£€æŸ¥
"""

import os
import sys
import json
import hashlib
from pathlib import Path
from typing import Dict, List, Any, Optional, Set
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from scripts.utils.logging_utils import get_script_logger
from scripts.utils.file_utils import read_json, write_json

class GlobalContextMonitor:
    """å…¨å±€ä¸Šä¸‹æ–‡ç›‘æ§å™¨"""

    def __init__(self):
        self.logger = get_script_logger("global_context_monitor")
        self.project_root = project_root
        self.context_config_path = self.project_root / "scripts" / "health" / "global_context_config.json"

        # å®šä¹‰éœ€è¦ç›‘æ§çš„å…³é”®è·¯å¾„
        self.critical_paths = {
            "src": self.project_root / "src",
            "web": self.project_root / "web",
            "scripts": self.project_root / "scripts",
            "docs": self.project_root / "docs",
            "assets": self.project_root / "assets",
            "rules": self.project_root / "rules",
            "logs": self.project_root / "logs",
            "tests": self.project_root / "tests"
        }

        # å®šä¹‰æ–‡ä»¶å…³è”æ˜ å°„
        self.file_associations = {
            ".py": ["__init__.py", "config.json", "_config.json", "_README.md"],
            ".js": [".min.js", ".map", ".config.js"],
            ".json": [".schema.json", "_config.json"],
            ".md": ["_README.md", ".md.template"],
            ".html": [".css", ".js"],
            ".css": [".min.css", ".map"]
        }

    def load_context_config(self) -> Dict[str, Any]:
        """åŠ è½½ä¸Šä¸‹æ–‡é…ç½®"""
        try:
            if self.context_config_path.exists():
                return read_json(self.context_config_path)
            else:
                default_config = {
                    "version": "1.0.0",
                    "last_scan": None,
                    "scan_interval": 3600,  # 1å°æ—¶
                    "critical_paths": list(self.critical_paths.keys()),
                    "file_associations": self.file_associations,
                    "exclusions": [".git", "__pycache__", ".pytest_cache", "node_modules"],
                    "monitoring": {
                        "enabled": True,
                        "real_time": False,
                        "alerts": True
                    }
                }
                write_json(self.context_config_path, default_config)
                return default_config
        except Exception as e:
            self.logger.error(f"åŠ è½½ä¸Šä¸‹æ–‡é…ç½®å¤±è´¥: {e}")
            return {}

    def scan_project_structure(self) -> Dict[str, Any]:
        """æ‰«æé¡¹ç›®ç»“æ„"""
        scan_result = {
            "timestamp": datetime.now().isoformat(),
            "total_files": 0,
            "total_dirs": 0,
            "path_status": {},
            "file_associations": {},
            "orphaned_files": [],
            "missing_associations": [],
            "integrity_issues": []
        }

        config = self.load_context_config()
        exclusions = set(config.get("exclusions", []))

        for path_name, path_obj in self.critical_paths.items():
            if not path_obj.exists():
                scan_result["path_status"][path_name] = "missing"
                scan_result["integrity_issues"].append(f"å…³é”®è·¯å¾„ä¸å­˜åœ¨: {path_name}")
                continue

            scan_result["path_status"][path_name] = "exists"

            # é€’å½’æ‰«æè·¯å¾„
            for root, dirs, files in os.walk(path_obj):
                # æ’é™¤ä¸éœ€è¦çš„ç›®å½•
                dirs[:] = [d for d in dirs if d not in exclusions]

                scan_result["total_dirs"] += len(dirs)
                scan_result["total_files"] += len(files)

                # æ£€æŸ¥æ–‡ä»¶å…³è”æ€§
                for file in files:
                    file_path = Path(root) / file
                    self.check_file_associations(file_path, scan_result)

        return scan_result

    def check_file_associations(self, file_path: Path, scan_result: Dict[str, Any]):
        """æ£€æŸ¥æ–‡ä»¶å…³è”æ€§"""
        file_ext = file_path.suffix
        file_name = file_path.name
        dir_path = file_path.parent

        # æ£€æŸ¥å…³è”æ–‡ä»¶
        expected_associations = self.file_associations.get(file_ext, [])

        for assoc in expected_associations:
            if assoc.startswith("."):
                # æ‰©å±•åå…³è”
                expected_file = file_path.with_suffix(assoc)
            else:
                # æ–‡ä»¶åå…³è”
                expected_file = dir_path / assoc

            if not expected_file.exists():
                scan_result["missing_associations"].append({
                    "file": str(file_path),
                    "expected": str(expected_file),
                    "type": "association"
                })

        # æ£€æŸ¥å­¤ç«‹æ–‡ä»¶
        if self.is_orphaned_file(file_path):
            scan_result["orphaned_files"].append(str(file_path))

    def is_orphaned_file(self, file_path: Path) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºå­¤ç«‹æ–‡ä»¶"""
        # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„é…ç½®æ–‡ä»¶
        if file_path.suffix == ".py":
            config_file = file_path.with_suffix("_config.json")
            readme_file = file_path.with_suffix("_README.md")
            if not config_file.exists() and not readme_file.exists():
                return True

        # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„æºæ–‡ä»¶
        if file_path.suffix in [".min.js", ".min.css", ".map"]:
            base_name = file_path.name.split(".")[0]
            source_file = file_path.parent / f"{base_name}{file_path.suffix.replace('.min', '').replace('.map', '')}"
            if not source_file.exists():
                return True

        return False

    def check_global_context_integrity(self) -> Dict[str, Any]:
        """æ£€æŸ¥å…¨å±€ä¸Šä¸‹æ–‡å®Œæ•´æ€§"""
        integrity_report = {
            "config_consistency": {},
            "path_references": {},
            "import_dependencies": {},
            "cross_references": {},
            "issues": []
        }

        # æ£€æŸ¥é…ç½®æ–‡ä»¶ä¸€è‡´æ€§
        config_files = [
            "project_config.json",
            "src/src_config.json",
            "web/web_config.json",
            "scripts/scripts_config.json"
        ]

        for config_file in config_files:
            config_path = self.project_root / config_file
            if config_path.exists():
                try:
                    config = read_json(config_path)
                    integrity_report["config_consistency"][config_file] = "valid"

                    # æ£€æŸ¥è·¯å¾„å¼•ç”¨
                    self.check_path_references(config, config_file, integrity_report)

                except Exception as e:
                    integrity_report["config_consistency"][config_file] = f"invalid: {e}"
                    integrity_report["issues"].append(f"é…ç½®æ–‡ä»¶æŸå: {config_file}")

        # æ£€æŸ¥Pythonå¯¼å…¥ä¾èµ–
        self.check_python_imports(integrity_report)

        # æ£€æŸ¥è·¨å¼•ç”¨
        self.check_cross_references(integrity_report)

        return integrity_report

    def check_path_references(self, config: Dict[str, Any], config_file: str, integrity_report: Dict[str, Any]):
        """æ£€æŸ¥è·¯å¾„å¼•ç”¨"""
        def check_paths(obj, path=""):
            if isinstance(obj, dict):
                for key, value in obj.items():
                    current_path = f"{path}.{key}" if path else key
                    if isinstance(value, (str, Path)) and str(value).startswith("/"):
                        full_path = self.project_root / str(value).lstrip("/")
                        if not full_path.exists():
                            integrity_report["path_references"][f"{config_file}:{current_path}"] = "broken"
                        else:
                            integrity_report["path_references"][f"{config_file}:{current_path}"] = "valid"
                    else:
                        check_paths(value, current_path)
            elif isinstance(obj, list):
                for i, item in enumerate(obj):
                    check_paths(item, f"{path}[{i}]")

        check_paths(config)

    def check_python_imports(self, integrity_report: Dict[str, Any]):
        """æ£€æŸ¥Pythonå¯¼å…¥ä¾èµ–"""
        python_files = list(self.project_root.rglob("*.py"))

        for py_file in python_files:
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()

                # æŸ¥æ‰¾å¯¼å…¥è¯­å¥
                import_lines = []
                for line in content.split('\n'):
                    line = line.strip()
                    if line.startswith(('import ', 'from ')):
                        import_lines.append(line)

                # åˆ†æå¯¼å…¥ä¾èµ–
                for import_line in import_lines:
                    if 'from src.' in import_line or 'from scripts.' in import_line:
                        # æ£€æŸ¥ç›¸å¯¹å¯¼å…¥
                        module_path = import_line.split('from ')[1].split(' import')[0]
                        if not self.check_module_exists(module_path):
                            integrity_report["import_dependencies"][str(py_file)] = f"missing: {module_path}"

            except Exception as e:
                self.logger.warning(f"æ£€æŸ¥å¯¼å…¥å¤±è´¥: {py_file}")

    def check_module_exists(self, module_path: str) -> bool:
        """æ£€æŸ¥æ¨¡å—æ˜¯å¦å­˜åœ¨"""
        try:
            parts = module_path.split('.')
            current_path = self.project_root

            for part in parts:
                current_path = current_path / part
                if not current_path.exists():
                    return False

                # æ£€æŸ¥æ˜¯å¦æœ‰__init__.py
                if current_path.is_dir() and not (current_path / "__init__.py").exists():
                    return False

            return True
        except:
            return False

    def check_cross_references(self, integrity_report: Dict[str, Any]):
        """æ£€æŸ¥è·¨å¼•ç”¨"""
        # æ£€æŸ¥æ–‡æ¡£å¼•ç”¨
        docs_path = self.project_root / "docs"
        if docs_path.exists():
            for md_file in docs_path.rglob("*.md"):
                try:
                    with open(md_file, 'r', encoding='utf-8') as f:
                        content = f.read()

                    # æŸ¥æ‰¾æ–‡ä»¶å¼•ç”¨
                    import re
                    refs = re.findall(r'\[([^\]]+)\]\(([^)]+)\)', content)
                    for text, link in refs:
                        if link.startswith(('../', './', '/')):
                            # ç›¸å¯¹è·¯å¾„å¼•ç”¨
                            full_path = (md_file.parent / link).resolve()
                            if not full_path.exists():
                                integrity_report["cross_references"][str(md_file)] = f"broken_link: {link}"

                except Exception as e:
                    self.logger.warning(f"æ£€æŸ¥æ–‡æ¡£å¼•ç”¨å¤±è´¥: {md_file}")

    def generate_integrity_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆå®Œæ•´æ€§æŠ¥å‘Š"""
        report = {
            "timestamp": datetime.now().isoformat(),
            "structure_scan": self.scan_project_structure(),
            "context_integrity": self.check_global_context_integrity(),
            "summary": {}
        }

        # ç”Ÿæˆæ‘˜è¦
        structure = report["structure_scan"]
        integrity = report["context_integrity"]

        report["summary"] = {
            "total_files": structure["total_files"],
            "total_dirs": structure["total_dirs"],
            "missing_paths": len([p for p in structure["path_status"].values() if p == "missing"]),
            "orphaned_files": len(structure["orphaned_files"]),
            "missing_associations": len(structure["missing_associations"]),
            "broken_references": len(integrity.get("path_references", {})),
            "import_issues": len(integrity.get("import_dependencies", {})),
            "cross_ref_issues": len(integrity.get("cross_references", {})),
            "overall_health": "good"
        }

        # è®¡ç®—æ•´ä½“å¥åº·åº¦
        issues_count = (
            report["summary"]["missing_paths"] +
            report["summary"]["orphaned_files"] +
            report["summary"]["missing_associations"] +
            report["summary"]["broken_references"] +
            report["summary"]["import_issues"] +
            report["summary"]["cross_ref_issues"]
        )

        if issues_count > 10:
            report["summary"]["overall_health"] = "critical"
        elif issues_count > 5:
            report["summary"]["overall_health"] = "warning"
        else:
            report["summary"]["overall_health"] = "good"

        return report

    def run(self):
        """è¿è¡Œå…¨å±€ä¸Šä¸‹æ–‡ç›‘æ§å™¨"""
        self.logger.info("å…¨å±€ä¸Šä¸‹æ–‡ç›‘æ§å™¨å¯åŠ¨")

        print("=" * 60)
        print("ğŸ” AIå¼¹çª—é¡¹ç›®å…¨å±€ä¸Šä¸‹æ–‡ç›‘æ§å™¨")
        print("=" * 60)

        # ç”Ÿæˆå®Œæ•´æ€§æŠ¥å‘Š
        report = self.generate_integrity_report()

        print(f"æ‰«ææ—¶é—´: {report['timestamp']}")
        print(f"é¡¹ç›®å¥åº·åº¦: {report['summary']['overall_health'].upper()}")

        print("\nğŸ“Š ç»“æ„ç»Ÿè®¡:")
        print(f"- æ€»æ–‡ä»¶æ•°: {report['summary']['total_files']}")
        print(f"- æ€»ç›®å½•æ•°: {report['summary']['total_dirs']}")
        print(f"- ç¼ºå¤±è·¯å¾„: {report['summary']['missing_paths']}")
        print(f"- å­¤ç«‹æ–‡ä»¶: {report['summary']['orphaned_files']}")
        print(f"- ç¼ºå¤±å…³è”: {report['summary']['missing_associations']}")

        print("\nğŸ”— å¼•ç”¨æ£€æŸ¥:")
        print(f"- æ–­å¼€å¼•ç”¨: {report['summary']['broken_references']}")
        print(f"- å¯¼å…¥é—®é¢˜: {report['summary']['import_issues']}")
        print(f"- è·¨å¼•ç”¨é—®é¢˜: {report['summary']['cross_ref_issues']}")

        # æ˜¾ç¤ºé—®é¢˜è¯¦æƒ…
        issues = []
        issues.extend(report["structure_scan"].get("integrity_issues", []))
        issues.extend(report["context_integrity"].get("issues", []))

        if issues:
            print("\nâš ï¸ å‘ç°é—®é¢˜:")
            for issue in issues[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªé—®é¢˜
                print(f"- {issue}")
            if len(issues) > 10:
                print(f"- ... è¿˜æœ‰ {len(issues) - 10} ä¸ªé—®é¢˜")

        # ä¿å­˜æŠ¥å‘Š
        report_path = self.project_root / "logs" / f"context_integrity_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        write_json(report_path, report)

        print(f"\nâœ… å®Œæ•´æ€§æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

        self.logger.info("å…¨å±€ä¸Šä¸‹æ–‡ç›‘æ§å™¨è¿è¡Œå®Œæˆ")

if __name__ == "__main__":
    monitor = GlobalContextMonitor()
    monitor.run()
